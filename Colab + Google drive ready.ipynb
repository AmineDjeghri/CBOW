{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Google drive ready.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMCqUnk7gj5l4ibQUBvbxmH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{},"source":["# Word Embeddings: CBOW"]},{"cell_type":"code","metadata":{"id":"wJj0DR_j-OX4","colab_type":"code","colab":{}},"source":["# # connect to google drive and move to the selected directory\n","# from google.colab import drive\n","# drive.mount('/content/gdrive')\n","# %cd \"/content/gdrive/MyÂµ Drive\" #select the current working derectory\n","# !pwd \n","# !ls "],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"23t0Jl5a9SEt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1596100389540,"user_tz":-120,"elapsed":3698,"user":{"displayName":"Amine Djeghri","photoUrl":"","userId":"06388183709028540430"}},"outputId":"f0a237d9-ad24-48b5-b764-ce5ef9427c61","tags":[]},"source":["#REQUIRED: ACTIVATE the gpu: (In the menu tabs, \"Runtime\" => \"Change runtime type and select gpu) \n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from tqdm import trange\n","import matplotlib.pyplot as plt\n","torch.manual_seed(1)\n","CUDA = torch.cuda.is_available()\n","print(\"avaible GPUs:\",torch.cuda.device_count())\n","# print(\"GPU name:\",torch.cuda.get_device_name())"],"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":"avaible GPUs: 0\n"}]},{"cell_type":"code","execution_count":104,"metadata":{"tags":[]},"outputs":[{"output_type":"error","ename":"UnicodeDecodeError","evalue":"'charmap' codec can't decode byte 0x9d in position 469: character maps to <undefined>","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)","\u001b[1;32m<ipython-input-104-e53687253989>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m we conjure the spirits of the computer with our spells'''\n\u001b[0;32m      7\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/en.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/en.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 469: character maps to <undefined>"]}],"source":["text = '''We are about to study the idea of a computational process.\n","Computational processes are abstract beings that inhabit computers.\n","As they evolve, processes manipulate other abstract things called data.\n","The evolution of a process is directed by a pattern of rules\n","called a program. People create programs to direct processes. In effect,\n","we conjure the spirits of the computer with our spells'''\n","\n","with open(\"data/en.txt\", \"r\") as f:\n","    text=f.read()\n"]},{"cell_type":"code","metadata":{"id":"m7bWIz4gBYEv","colab_type":"code","colab":{},"tags":[]},"source":["\n","class CBOW(nn.Module):\n","    \"\"\"\"\n","    Word2Vec CBOW model\n","    \"\"\"\n","    def __init__(self, vocab_size, embedding_size, context_size):\n","        super().__init__()\n","        self.embeddings = nn.Embedding(vocab_size, embedding_size)\n","        \n","        if CUDA:\n","            self.embeddings = self.embeddings.cuda()\n","        self.linear1 = nn.Linear(embedding_size, 128)\n","        self.linear2 = nn.Linear(128, vocab_size)\n","        \n","    def forward(self, inputs):\n","        out = self.embeddings(inputs).mean( dim=0).view((1, -1))\n","        \n","        out=self.linear1(out)\n","        out=F.relu(out)\n","        out=self.linear2(out)\n","        out=F.log_softmax(out,dim=1)\n","        return out\n","\n","    def predict(self,input):\n","        ##\n","        return 0\n","\n","def preprocess_text(text, context_size):\n","    '''\n","    Convert text to data:(context, target) for training cbow model\n","\n","    Parameters:\n","        text (String): text to preprocess\n","        context_size (int): the context window \n","    \n","    Return:\n","        data (tuple): data in form of (context, target)\n","        words_to_idx(dict): dict containing a mapping word->index\n","    '''\n","    text=text.lower().split()\n","    #build contexts and targets\n","    data = list()   \n","    for i in range(context_size, len(text) - context_size):\n","        context = [text[i+j] for j in range(-context_size, context_size+1) if i+j != i]\n","        target = text[i]  \n","        data.append((context, target))\n","    \n","    # map words to index\n","    vocab=set(text)\n","    words_to_idx = {w: i for i, w in enumerate(vocab)}\n","    return data,words_to_idx\n","\n","def words_to_tensor(words,word_to_idx):\n","    '''\n","    Retrieve the indexes of given words\n","\n","    Parameters:\n","        words (list of string): \n","    \n","    Return:\n","        tensor (Tensor): tensor of indexes \n","    '''\n","\n","    tensor =torch.LongTensor([word_to_idx[word] for word in words])\n","\n","    if CUDA:\n","        tensor = tensor.cuda()\n","\n","    return tensor   \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["CONTEXT_SIZE=2\n","EMBEDDING_SIZE=300\n","EPOCHS=5\n","LEARNING_RATE = 0.001\n","\n","model=CBOW(len(words_to_idx),EMBEDDING_SIZE,CONTEXT_SIZE) \n","data,words_to_idx=preprocess_text(text,context_size=2)\n","idx_to_words = {v: k for k, v in words_to_idx.items()}\n","\n","def train(model,data,words_to_idx):\n","    '''\n","    Train a model \n","\n","    Parameters:\n","        model (nn.module):\n","        data(list of tuples):  \n","        words_to_idx() :dict containing a mapping word->index\n","    Return:\n","        tensor (Tensor): \n","    '''\n","    loss_func = torch.nn.NLLLoss()\n","    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n","    losses=[]\n","\n","    for epoch in trange(EPOCHS):\n","        total_loss=0\n","        for context,target in data:\n","            context_idx=words_to_tensor(context,words_to_idx)\n","            target_idx=words_to_tensor([target],words_to_idx)\n","            model.zero_grad\n","            output=model(context_idx)\n","            loss = loss_func(output, target_idx)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","        losses.append(total_loss)\n","    \n","    \n","    plt.figure()\n","    plt.plot(losses)\n","    plt.show()\n","train(model,data,words_to_idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["\n","def get_prediction(context, model,words_to_idx,idx_to_words):\n","    \"\"\"\"\n","    Predict a word from a given context\n","\n","    Parameters: \n","        context(List of string): \n","        model:\n","        words_to_idx(Tensor):\n","        idx_to_words(dict):dict containing a mapping index->word\n","    Return:\n","        (String): predicted word\n","    \"\"\"\n","    model.eval()\n","    prediction = model(words_to_tensor(context, words_to_idx))\n","    _, index = torch.max(prediction, 1)\n","    return idx_to_words[index.item()]\n","\n","def check_accuracy(model,data,words_to_idx,idx_to_words):\n","\n","    \"\"\"\"\n","    Check accuracy\n","\n","    Parameters: \n","        data(list): list of tuples(context,target) \n","        model:\n","        words_to_idx(dict):dict containing a mapping word->index\n","        idx_to_words(dict):dict containing a mapping index->word\n","    Return:\n","        (String): predicted word\n","    \"\"\"\n","\n","    correct = 0\n","    for context, target in data:\n","        prediction = get_prediction(context, model,words_to_idx,idx_to_words)\n","        if prediction == target:\n","            correct += 1\n","    return correct/len(data)\n","\n","print(check_accuracy(model,data,words_to_idx,idx_to_words))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(get_prediction(['as' ,'the','strange' ,'beings'],model,words_to_idx,idx_to_words))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}